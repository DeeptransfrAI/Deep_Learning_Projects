{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object-Detection(Recognition).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1oSL7ZR0JV6GRfOM0X1tPlITbdxnEJfV1",
      "authorship_tag": "ABX9TyMQ0h6XfazrB7vhlSM38d0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeeptransfrAI/Deep_Learning_Projects/blob/master/Object_Detection(Recognition).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRu7SdlhIlvw",
        "colab_type": "text"
      },
      "source": [
        "### Now Lets Create Our YOLOv3 CNN\n",
        "-Once weights have been download and our Yolov3 model has been saved, lets begin building!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsp7qwthHzFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libs\n",
        "import struct\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.merge import add, concatenate\n",
        "\n",
        "#create first conv block\n",
        "def _conv_block(inp,convs,skip = True):\n",
        "  x = inp\n",
        "  count = 0\n",
        "  #create function for conv\n",
        "  for conv in convs:\n",
        "    if count == (len(convs)-2) and skip:\n",
        "      skip_connection = x\n",
        "    count += 1\n",
        "    if conv['stride'] > 1:x = ZeroPadding2D(((1,0),(1,0)))(x)\n",
        "    #create conv2d layer\n",
        "    x = Conv2D(conv['filter'],\n",
        "               conv['kernel'],\n",
        "               strides = conv['stride'],\n",
        "               padding = 'valid' if conv['stride'] else 'same',\n",
        "               name ='conv_' + str(conv['layer_idx']),\n",
        "               use_bias = False if conv['bnorm'] else True)(x)\n",
        "    if conv['bnorm']: x = BatchNormalization(epsilon = 0.001,\n",
        "                                             name ='bnorm_' + str(conv['layer_idx']))(x)\n",
        "    if conv['leaky']: x = LeakyReLU(alpha = 0.1, \n",
        "                                    name ='leaky_' + str(conv['layer_idx']))(x)\n",
        "  return add([skip_connection, x]) if skip else x  \n",
        "\n",
        "#define yolo v3 model\n",
        "def make_yolov3_model():\n",
        "  input_image = Input(shape=(None,None,3))\n",
        "  #layers 0=>4\n",
        "  x = _conv_block(input_image,\n",
        "                  [{'filter': 32, 'kernel':3, 'stride':1, 'bnorm':True, 'leaky':True, 'layer_idx':0},\n",
        "                   {'filter':64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                   {'filter':32, 'kernel':1, 'stride':1, 'bnorm': True, 'leaky': True, 'layer_idx': 2 },\n",
        "                   {'filter':64, 'kernel':3, 'stride':1, 'bnorm': True, 'leaky': True, 'layer_idx':3}])\n",
        "  #layers 5=>8\n",
        "  x = _conv_block(x,\n",
        "                 [{'filter': 128, 'kernel': 3, 'stride':2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                  {'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                  {'filter': 128, 'kernel':3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "  #layers 9=>11\n",
        "  x = _conv_block(x, \n",
        "                  [{'filter': 64, 'kernel': 1, 'stride':1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                   {'filter': 128, 'kernel':3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "  #layers 12=> 15\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 256, 'kernel': 3, 'stride':2, 'bnorm': True, 'leaky':True, 'layer_idx':12},\n",
        "                   {'filter': 128, 'kernel': 1,'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                   {'filter': 256, 'kernel': 3, 'stride':1, 'bnorm': True, 'leaky':True, 'layer_idx': 14}])\n",
        "  #layers 16=>36 \n",
        "  #format layed out slightly diff\n",
        "  for i in range(7):\n",
        "    x = _conv_block(x,\n",
        "                    [{'filter': 128, 'kernel': 1, 'stride':1, 'bnorm': True, 'leaky':True, 'layer_idx': 16+i*3},\n",
        "                     {'filter': 256, 'kernel': 3, 'stride':1, 'bnorm':True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "  skip_36 = x\n",
        "  #layers 37=>40\n",
        "  #same layer as earlier layers\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm':True, 'leaky': True, 'layer_idx': 37},\n",
        "                   {'filter':256, 'kernel':1, 'stride': 1, 'bnorm':True, 'leaky': True, 'layer_idx': 38},\n",
        "                   {'filter':512, 'kernel':3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 39}])\n",
        "  #layer 41=>61\n",
        "  #diiferent layout as 16=>36\n",
        "  for i in range(7):\n",
        "    x = _conv_block(x,\n",
        "                    [{'filter': 256, 'kernel':1, 'stride':1, 'bnorm': True, 'leaky':True, 'layer_idx': 41+i*3},\n",
        "                     {'filter': 512, 'kernel':3, 'stride':1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "  skip_61 = x\n",
        "  #62=>65\n",
        "  #same as earlier layouts\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky':True, 'layer_idx': 62},\n",
        "                   {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                    {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "  #layer 66=>74\n",
        "  #diff layout format\n",
        "  for i in range(3):\n",
        "    x = _conv_block(x,\n",
        "                    [{'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx':66+i*3},\n",
        "                     {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 67+i*3}])\n",
        "    #layers 75=> 79\n",
        "    #original layout ,includes skip = False very end\n",
        "    x = _conv_block(x,\n",
        "                    [{'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm':True, 'leaky':True, 'layer_idx': 75},\n",
        "                     {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 76},\n",
        "                     {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm':True, 'leaky': True, 'layer_idx':77},\n",
        "                     {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 78},\n",
        "                     {'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx':79}],\n",
        "                    skip = False)\n",
        "  # layers 80=>82\n",
        "  #includes yolo 82 layer\n",
        "  #filter also drops dramatically on second layer\n",
        "  yolo_82= _conv_block(x,\n",
        "                       [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 80},\n",
        "                        {'filter': 255,'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}],\n",
        "                       skip = False)\n",
        "  #layer 83=>86\n",
        "  #diff layout\n",
        "  #will include upsampling and concatenate\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 84}],\n",
        "                  skip=False)\n",
        "  x = UpSampling2D(2)(x)\n",
        "  x = concatenate([x, skip_61])\n",
        "\n",
        "  #layers 87=>91\n",
        "  #pretty similar to previous layers\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 87},\n",
        "                   {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 88},\n",
        "                   {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 89},\n",
        "                   {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 90},\n",
        "                   {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky':True, 'layer_idx': 91}],\n",
        "                  skip = False)\n",
        "  #layers 92=>94\n",
        "  #using yolo_94\n",
        "  #second layer drops heavily\n",
        "  yolo_94 = _conv_block(x,\n",
        "                        [{'filter': 512, 'kernel': 3, 'stride':1, 'bnorm': True, 'leaky':True, 'layer_idx': 92},\n",
        "                         {'filter': 255, 'kernel': 1, 'stride':1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}],\n",
        "                        skip = False)\n",
        "  #layer 95=>98\n",
        "  #diff layout includedss upsampling and concatentate\n",
        "  x = _conv_block(x,\n",
        "                  [{'filter': 512, 'kernel':3, 'stride':1, 'bnorm':True, 'leaky': True, 'layer_idx': 96}],\n",
        "                  skip = False)\n",
        "  x = UpSampling2D(2)(x)\n",
        "  x = concatenate([x, skip_36])\n",
        "  #layers 99 =>106\n",
        "  #uses the yolo106\n",
        "  #last conv drops...not increases\n",
        "  yolo_106 = _conv_block(x,\n",
        "                         [{'filter':128, 'kernel':1, 'stride':1, 'bnorm':True, 'leaky':True, 'layer_idx': 99},\n",
        "                          {'filter': 256, 'kernel':3, 'stride':1, 'bnorm':True, 'leaky': True, 'layer_idx': 100},\n",
        "                          {'filter': 128, 'kernel': 1, 'stride':1, 'bnorm': True, 'leaky': True, 'layer_idx': 101},\n",
        "                          {'filter':256, 'kernel':3, 'stride':1, 'bnorm':True, 'leaky':True, 'layer_idx': 102},\n",
        "                         {'filter':128, 'kernel': 1, 'stride':1,'bnorm':True, 'leaky':True, 'layer_idx': 103},\n",
        "                         {'filter': 256, 'kernel':3, 'stride':1, 'bnorm':True, 'leaky':True, 'layer_idx': 104},\n",
        "                         {'filter': 255, 'kernel': 1, 'stride':1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}],\n",
        "                         skip = False)\n",
        "  model = Model(input_image, [yolo_82,yolo_94,yolo_106])\n",
        "  return model\n",
        "  \n",
        "class WeightReader:\n",
        "  def __init__(self, weight_file):\n",
        "    with open(weight_file, 'rb') as w_f:\n",
        "      major, = struct.unpack('i', w_f.read(4))\n",
        "      minor, = struct.unpack('i', w_f(4))\n",
        "      revision, = struct.unpack('i',w_f(4))\n",
        "      if (major*10 + minor) >=2 and major < 1000 and minor < 1000:\n",
        "        w_f.read(8)\n",
        "      else:\n",
        "        w_f.read(4)\n",
        "        transpose = (major > 1000) or (minor > 1000)\n",
        "        binary = w_f.read()\n",
        "      self.offset = 0\n",
        "      self.all_weights = np.frombuffer(binary, dtype ='float32')\n",
        "\n",
        "  def read_bytes(self, size):\n",
        "    self.offset = self.offset + size\n",
        "    return self.all_weights[self.offset-size:self.offset]\n",
        "  \n",
        "  def load_weights(self, model):\n",
        "    for i in range(106):\n",
        "      try:\n",
        "        conv_layer = model.get_layer('conv_' + str(i))\n",
        "        print('loading weights of convolution #' + str(i))\n",
        "        if i not in [81,93,105]:\n",
        "          norm_layer = model.get_layer('bnorm' + str(i))\n",
        "          size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "          beta = self.read.bytes(size) # bias\n",
        "          gamma = self.read_bytes(size) # scale\n",
        "          mean = self.read_bytes(size) #mean\n",
        "          var = self.read_bytes(size) #variance\n",
        "          weights = norm_layer.set_weights([gamma,beta,mean,var])\n",
        "        if len (conv_layer.get_weights()) > 1:\n",
        "          bias = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "          kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "          kernel = kernel.transpose([2,3,1,0])\n",
        "          conv_layer.set_weights([kernel, bias])\n",
        "        else:\n",
        "          kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "          kernel = kernel.transpose([2,3,1,0])\n",
        "          conv_layer.set_weights([kernel])\n",
        "      except ValueError:\n",
        "        print('no convolution #' + str(i))\n",
        "  \n",
        "  def reset(self):\n",
        "    self.offset= 0\n",
        "\n",
        "#define the model\n",
        "model = make_yolov3_model()\n",
        "#load the model weights\n",
        "weight_reader = WeightReader('/gdrive/My Drive/Colab Notebooks/Model_Weights/yolov3.weights')\n",
        "#set the model weights into the model\n",
        "weight_reader.load_weights(model)\n",
        "#save modelto file\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkXEvFuJw3X",
        "colab_type": "text"
      },
      "source": [
        "### MAKE A PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b9rI3AvuTE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load yolov3 model and perform object detection\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "class BoundBox:\n",
        "  def __init__(self,xmin,ymin,xmax,ymax, objness = None, classes = None):\n",
        "    self.xmin = xmin\n",
        "    self.ymin = ymin\n",
        "    self.xmax = xmax\n",
        "    self.ymax = ymax\n",
        "    self.objness = objness\n",
        "    self.classes = classes\n",
        "    self.label = -1\n",
        "    self.score = -1\n",
        "\n",
        "def get_label(self):\n",
        "  if self.label == -1:\n",
        "    self.label = np.argmax(self.classes)\n",
        "  \n",
        "  return self.label\n",
        "\n",
        "def get.score(self):\n",
        "  if self.score == -1:\n",
        "    self.score = self.classes[self.get_label()]\n",
        "  \n",
        "  return self.score\n",
        "\n",
        "def _sigmoids(x):\n",
        "  return 1. / (1. + np.exp(-x))\n",
        "\n",
        "\n",
        "def decode_netout(netout,anchors, obj_thresh, net_h, net_w):\n",
        "  grid_h, grid_w = netout.shape[:2]\n",
        "  nb_box = 3\n",
        "  netout = netout.reshape((grid-h, grid_w, nb_box, -1))\n",
        "  nb_class = netout.shape[-1] - 5\n",
        "  boxes = []\n",
        "  netout[..., :2] = _sigmoid(netout[...,:2])\n",
        "  netout[....,4:] = _sigmoid(netout[...,4:])\n",
        "  netout[...,5:] = netout[...,4][...,np.newaxis] * netout[...,5:]\n",
        "  netout[...,5:] *= netout[...,5:] > obj_thresh\n",
        "\n",
        "  for i in range(grid_h * grid_w):\n",
        "    row = i / grid_w\n",
        "    col = i % grid_w\n",
        "    for b in range(nb_box):\n",
        "      #4th element is objectness score\n",
        "      objectness = netout[int(row)][int(col)][b][:4]\n",
        "      if(objectness.all() <= obj_thresh): continue\n",
        "      #first 4 elements are x, y,w,h\n",
        "      x,y,w,h = netout[int(row)][int(col)][b][:4]\n",
        "      x = (col + x)/ grid_w #center position, unit: image width\n",
        "      y = (row + y) /grid_h #center position, unit: image height\n",
        "      w = anchors[2 * b + 0] * np.exp(w)/ net_w   #unit: image width\n",
        "      h = anchors[2 * b + 1] * np.exp(h) / net_h   #unit: image height\n",
        "      #last elements are class probabilities\n",
        "      classes = netout[int(row)][col][b][5:]\n",
        "      box = BoundBox(x -w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "      boxes.append(box)\n",
        "  return boxes\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_h,image_w, net_h, net_w):\n",
        "  new_w, new_h = net_w, net_h\n",
        "  for i in range(len(boxes)):\n",
        "    x_offset, x_scale =(net_w - new_w)/2.net_w, float(new_w)/net_w\n",
        "    y_offset, y_scales = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "    boxes[i].xmin = int((boxes[i].xmin-x_offset)/x_scale * image_w)\n",
        "    boxes[i].xmax = int(boxes[i].xmax - x_offset)/ x_scale * image_w)\n",
        "    boxes[i].ymin = int(boxes[i].ymin - y_offset)/ y_scale * image_h)\n",
        "    boxes[i].ymax = int(boxes[i].ymax - y_offset)/ y_scale * image_h)\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "  x1,x2 = interval_a\n",
        "  x3, x4 = interval_b\n",
        "  if x3 < x1:\n",
        "    if x4 < x1:\n",
        "      return 0\n",
        "    else:\n",
        "      return min(x2,x4) - x1\n",
        "  else:\n",
        "    if x2 < x3:\n",
        "      return 0\n",
        "    else:\n",
        "      retur.min(x2,x4) - x3\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "  intersect_w = _interval_overlap([box1.xmin,box1.xmax], [box2.xmin, box2.xmax])\n",
        "  intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "  intersect = intersect_w * intersect_h\n",
        "  w1,h1 = box1.xmax-box1.xmin, box1.ymax - box1.ymin\n",
        "  w2,h2 = box2.xmax = box2.xmin, box2.ymax - box2.ymin\n",
        "  union = w1*h1 + w2*h2 - intersect\n",
        "  return float(intersect)/ union \n",
        "\n",
        "def do,_nms(boxes,nms_thresh):\n",
        "  if len(boxes) > 0:\n",
        "    nb_class = len(boxes[0].classes)\n",
        "  else:\n",
        "    return\n",
        "  for c in range(nb_class):\n",
        "    sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "    for i in range(len(sorted_indices)):\n",
        "      index_i = sorted_indices[i]\n",
        "      if boxes[index_i].classes[c] ==0: continue\n",
        "      for j in range(i + 1, len(sorted_indices)):\n",
        "        index_j = sorted_indices[j]\n",
        "        if bbox_iou(boxes[index_i], boxes[index_j]) >=nms_thresh:\n",
        "          boxes[index_j].classes[c] =0\n",
        "                          \n",
        "#load an prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "  #load image to get it's shape\n",
        "  image = load_img(filename)\n",
        "  width,height = image.size\n",
        "  #load the image with the required size\n",
        "  image = load_img(filename, target_size=shape)\n",
        "  #convet to array\n",
        "  image = img_to_array(image)\n",
        "  #scale pixel values between 0-1\n",
        "  image = image.astype('float32')\n",
        "  image /= 255.0\n",
        "  #add a dimension so that we have one sample\n",
        "  image = expand_dims(image,0)\n",
        "  return image, width, height\n",
        "\n",
        "#get all of the results above threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "  v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "  #enumerate all boxes\n",
        "  for box in boxes:\n",
        "    #enumerate all possible labels\n",
        "    for i in range(len(labels)):\n",
        "      #check if the threshold for this label is high enough\n",
        "      if box.classes[i]> thresh:\n",
        "        v_boxex.append(box)\n",
        "        v_labels.append(labels[i])\n",
        "        v_scores.append(box.classes[i]*100)\n",
        "        #don't breal, many labels may trigger for one box\n",
        "return v_boxes, v_labels, v_scores \n",
        "\n",
        "#draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "  #load image\n",
        "  data = pyplot.imread(filename)\n",
        "  #plot image\n",
        "  pyplot.imshow(data)\n",
        "  #get context for drawing boxes\n",
        "  ax = pyplot.gca()\n",
        "  #plot each box\n",
        "  for i in range(len(v_boxes)):\n",
        "    box = v_boxes[i]\n",
        "    #get coordinates\n",
        "    y1,x1,y2,x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "    #calculate width and heigh of the box\n",
        "    width, height = x2-x1, y2-y1\n",
        "    #create the shape\n",
        "    rect = Rectangle((x1,y1), width, height, fill = False, color='white')\n",
        "    #draw the box\n",
        "    ax.add_patch(rect)\n",
        "    #draw text abd score in top left corner\n",
        "    label = '%s (%.3f)' % (*v_labels[i], v_scores[i])\n",
        "    pyplot.text(x1,y1, label, color = 'white')\n",
        "  #show plot\n",
        "  pyplot.show()\n",
        "\n",
        "\n",
        "#load yolov3 model\n",
        "model = load_model('model_h5')\n",
        "#define the expected input shape of the model\n",
        "input_w, input_h = 416,416\n",
        "#define our new photo\n",
        "photo_filename = 'zebra.jpg'\n",
        "#load and prepare the image\n",
        "image, image_w, image_h = load_image_pixels(photo_filename,(input_w, input_h))\n",
        "#make prediction\n",
        "yhat = model.predict(image)\n",
        "#summarize shape of list of arrays\n",
        "print([a.shape for a in yhat])\n",
        "\n",
        "#define the anchors\n",
        "anchors = [[116,90,156,198,373,326], [30,61,62,45,59,119], [10,13,16,30,33,23]]\n",
        "\n",
        "#define the prob threshold for detedcted objects\n",
        "class_threshold = 0.6\n",
        "boxes = list()\n",
        "for i in range(len(yhat)):\n",
        "  #decode the output of the network\n",
        "  boxes += decode_netout(yhat[i][0],anchors[i], class_theshold,input-h,input_w)\n",
        "#correct the sizes of the bounding boxes for the shape of the image\n",
        "correct_yolo_boxes(boxes, image_h, image_w, input_h, inout_w)\n",
        "\n",
        "#suppress non maximal boxes\n",
        "do_nms(boxes,0.5)\n",
        "\n",
        "#define the labels\n",
        "labels = ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "          'fire hydrant', 'stop sign', 'parking mete', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\n",
        "          'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skies', \n",
        "          'snowboard', 'sports ball', 'kite', 'baseball hat', 'baseball glove', 'skateboard', 'surfoard','tennis racket',\n",
        "          'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwhich', 'orange', 'broccoli',\n",
        "          'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedlant', 'bed', 'dining table',\n",
        "          'toilet', 'tv monitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "          'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair dryer', 'toothbrush']\n",
        "#get the detailes of the detected objects\n",
        "v_boxes, v_labels, v_scores = get_boxes(boxes,labels, class_threshold)\n",
        "\n",
        "#summarize what we found\n",
        "for i in range(len(v_boxes)):\n",
        "  print(v_labels[i], v_scores[i])\n",
        "\n",
        "#draw what we found\n",
        "draw_boxes(photo_filename,v_boxes,v_labels,v_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}